{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":99243,"databundleVersionId":11858537,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install seaborn polars pandas numpy scikit-learn ydata_profiling -U -q #u = update , q = reduce output displayed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:10:13.825580Z","iopub.execute_input":"2025-04-18T22:10:13.825840Z","iopub.status.idle":"2025-04-18T22:10:27.888261Z","shell.execute_reply.started":"2025-04-18T22:10:13.825819Z","shell.execute_reply":"2025-04-18T22:10:27.887361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport polars as pl\nimport polars.selectors as cs\nimport matplotlib.pyplot as plt\nfrom ydata_profiling import ProfileReport\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport os\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:25:10.692261Z","iopub.execute_input":"2025-04-18T22:25:10.693129Z","iopub.status.idle":"2025-04-18T22:25:10.836240Z","shell.execute_reply.started":"2025-04-18T22:25:10.693093Z","shell.execute_reply":"2025-04-18T22:25:10.835520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pl.read_csv(\"/kaggle/input/csai-253-project-phase-2/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:32:51.103584Z","iopub.execute_input":"2025-04-18T22:32:51.103959Z","iopub.status.idle":"2025-04-18T22:32:51.538347Z","shell.execute_reply.started":"2025-04-18T22:32:51.103936Z","shell.execute_reply":"2025-04-18T22:32:51.537533Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nId: Unique identifier for each row in the test set.\nflow_time: Duration of network flow.\nheader_size: Size of the packet headers.\npacket_duration: Duration of individual packets.\noverall_rate: Overall data transfer rate.\nsrc_rate: Data transfer rate from the source.\ndst_rate: Data transfer rate towards the destination.\nfin_packets: Number of packets flagged as finished (FIN).\nurg_packets: Number of urgent packets (URG).\nrst_packets: Number of reset packets (RST).\nmax_value: Maximum value observed in packet data.\nsyn_flags: Number of SYN (synchronize) flags detected.\nrst_flags: Number of RST (reset) flags detected.\npsh_flags: Number of PSH (push) flags detected.\nack_flags: Number of ACK (acknowledge) flags detected.\nprotocol_http: Indicates HTTP protocol usage.\nprotocol_https: Indicates HTTPS protocol usage.\nprotocol_tcp: Indicates TCP protocol usage.\nprotocol_udp: Indicates UDP protocol usage.\nprotocol_icmp: Indicates ICMP protocol usage.\nlabel (only in train.csv): Type of cyber-attack to be predicted (e.g., DDoS, DoS, benign).\n\"\"\"\ndf.schema","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:10:34.420393Z","iopub.execute_input":"2025-04-18T22:10:34.420919Z","iopub.status.idle":"2025-04-18T22:10:34.427724Z","shell.execute_reply.started":"2025-04-18T22:10:34.420897Z","shell.execute_reply":"2025-04-18T22:10:34.427086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:19:27.404451Z","iopub.execute_input":"2025-04-18T22:19:27.404805Z","iopub.status.idle":"2025-04-18T22:19:27.598971Z","shell.execute_reply.started":"2025-04-18T22:19:27.404780Z","shell.execute_reply":"2025-04-18T22:19:27.598015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#how may classes do we have?\nprint(df[\"label\"].unique().value_counts().sum()[\"count\"][0] ,\" unique labels\")\ndf = df.with_columns(pl.col(\"label\").str.to_lowercase()) # case folding , expression object: pl.col(\"label\")\n#Are the classes un-balanced\nquickOVERVIEW = df[\"label\"].value_counts().with_columns((pl.col(\"count\")/df[\"label\"].shape[0] *100).alias(\"percentage\"))\nquickOVERVIEW","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:40:39.274970Z","iopub.execute_input":"2025-04-18T22:40:39.275775Z","iopub.status.idle":"2025-04-18T22:40:39.444814Z","shell.execute_reply.started":"2025-04-18T22:40:39.275751Z","shell.execute_reply":"2025-04-18T22:40:39.443806Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(20, 5), dpi=500)\nplt.bar(\n    quickOVERVIEW[\"label\"], \n    height=quickOVERVIEW[\"percentage\"] , \n    color= quickOVERVIEW[\"label\"].replace({\n    \"ddos\": \"red\",             \n    \"recon\": \"blue\",           \n    \"benigntraffic\": \"green\", \n    \"mitm\": \"orange\",          \n    \"dos\": \"purple\",          \n    \"mirai\": \"cyan\"           \n}\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:42:36.528956Z","iopub.execute_input":"2025-04-18T22:42:36.529350Z","iopub.status.idle":"2025-04-18T22:42:37.728292Z","shell.execute_reply.started":"2025-04-18T22:42:36.529325Z","shell.execute_reply":"2025-04-18T22:42:37.727092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"profile = ProfileReport(df.to_pandas(), title=\"Profiling Report\" , explorative=True , lazy= True , minimal = True)\n# Display the report (Kaggle should automatically render it)\nprofile.to_notebook_iframe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:10:35.949741Z","iopub.execute_input":"2025-04-18T22:10:35.950056Z","iopub.status.idle":"2025-04-18T22:10:52.001302Z","shell.execute_reply.started":"2025-04-18T22:10:35.950028Z","shell.execute_reply":"2025-04-18T22:10:51.999975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(20, 5), dpi=500)\n\nsns.boxplot(\n    data=ScaledFeatures,#numeric columns only\n    showfliers=False,  # hide extreme outliers\n    boxprops=dict(facecolor=\"lightblue\", linewidth=2),  # box styling\n    whiskerprops=dict(color=\"blue\", linewidth=2, linestyle=\"--\"),\n    medianprops=dict(color=\"darkred\", linewidth=2),\n    capprops=dict(color=\"blue\", linewidth=2),\n    # gap=1.5\n)\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:27:46.697495Z","iopub.execute_input":"2025-04-18T22:27:46.698319Z","iopub.status.idle":"2025-04-18T22:28:33.030030Z","shell.execute_reply.started":"2025-04-18T22:27:46.698296Z","shell.execute_reply":"2025-04-18T22:28:33.029088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[[col for i, col in enumerate(df.columns) if i == 0 or i==3 or i==4 or i==9]].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:29:43.952592Z","iopub.execute_input":"2025-04-18T22:29:43.952980Z","iopub.status.idle":"2025-04-18T22:29:44.028855Z","shell.execute_reply.started":"2025-04-18T22:29:43.952957Z","shell.execute_reply":"2025-04-18T22:29:44.027951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ScaledFeatures =  StandardScaler().fit_transform(df.select(cs.numeric()))\ndf = pl.concat(items = [pl.DataFrame(ScaledFeatures , schema = df.select(cs.numeric()).columns) , df.select(\"label\")] ,  how=\"horizontal\")\nd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T22:37:57.280518Z","iopub.execute_input":"2025-04-18T22:37:57.281221Z","iopub.status.idle":"2025-04-18T22:37:57.698991Z","shell.execute_reply.started":"2025-04-18T22:37:57.281167Z","shell.execute_reply":"2025-04-18T22:37:57.697942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#feature selection \nselector = SelectKBest(score_func=f_classif, k=10)\n\nselector.fit(df.select(cs.numeric()), df[\"label\"])\n\nselected_indices = selector.get_support(indices=True)\nprint(selected_indices , len(selected_indices),\"features\")\nselected_features = [df.select(cs.numeric()).columns[i] for i in selected_indices]\nprint(\"\\nSelected features: \\n\", selected_features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# not as we did in phase 1 , we will be testing undersampling and oversampling, \n# validated my idea by generative pre-trained transformers\n\n\"\"\"You're dealing with a pretty classic **class imbalance problem**, especially with `\"ddos\"` being massively overrepresented and `\"benigntraffic\"`, `\"mitm\"`, and `\"recon\"` heavily underrepresented.\n\nHere's a breakdown of your idea, and some suggestions:\n\n---\n\n### âœ… Your Plan (Under + Over Sampling):\nUsing **undersampling on the majority (\"ddos\")** and then **oversampling the minority classes** is totally reasonable and commonly done. Here's how it might work:\n\n#### Step-by-step version of your plan:\n1. **Undersample \"ddos\"** to reduce its impact.\n2. **Oversample \"benigntraffic\", \"mitm\", \"recon\"**, and maybe even \"mirai\" to get a more balanced dataset.\n3. **Possibly leave \"dos\" as is**, or slightly adjust it.\n\n---\n\n### ğŸ§  Tips on Executing It:\n\n#### 1. âš–ï¸ **Target Balance Strategy**\nDecide your final desired sample size per class. Example ideas:\n- Match to the size of \"mirai\" (~50K)\n- Or go a bit lower to reduce training size, say ~30K per class\n- Avoid exact balance â€” slight randomness can help generalization\n\n#### 2. ğŸ§¹ **Undersampling \"ddos\"**\nYou can randomly select ~30Kâ€“50K rows from \"ddos\" (from 687K). Make sure to **shuffle** before picking.\n\n#### 3. ğŸ” **Oversampling Minorities**\nUse techniques like:\n- **Random Oversampling** (e.g., simple duplication)\n- **SMOTE/ADASYN** (synthetic data generation, if the features support it â€” i.e., numeric and continuous)\n\n> Note: SMOTE doesnâ€™t work well with categorical data unless encoded carefully.\n\n#### 4. ğŸ§ª **Be Careful with Oversampling**\nIf you're evaluating on the same dataset, make sure not to **leak duplicated synthetic samples into your validation set** â€” only oversample in the training split.\n\n---\n\n### âš–ï¸ Alternative: Use Class Weights\nIf you're using tree-based models (like XGBoost, LightGBM) or neural nets, consider using **class weighting** instead. It avoids changing the actual data and simply adjusts the cost of misclassification.\n\n---\n\n### ğŸ‘€ Example Target Distribution\n| Label          | Target Count |\n|----------------|--------------|\n| ddos           | 30,000       |\n| benigntraffic  | 30,000       |\n| mitm           | 30,000       |\n| mirai          | 30,000       |\n| recon          | 30,000       |\n| dos            | 30,000       |\n\nYou could tune this depending on whether you want full balance or slight realism.\n\n---\n\n### ğŸ“¦ TL;DR\n- Your under+over strategy is solid.\n- Make sure not to leak synthetic samples into validation/test.\n- Consider class weights as a simpler alternative if supported.\n- Donâ€™t overdo oversampling â€” can lead to overfitting if minority class is too tiny.\n\nWould you like help with writing some code to implement this in Python (e.g., using `pandas`, `sklearn`, `imbalanced-learn`)?\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Just a tester\n\n\nX_train, X_test, y_train, y_test = train_test_split(df.select(selected_features), df[\"label\"], test_size=0.25, random_state=42)\n\n\nrf_model = RandomForestClassifier(random_state=42, class_weight=\"balanced\" , n_jobs=-1)  # class_weight=\"balanced\" helps with imbalance\nrf_model.fit(X_train, y_train)\n\n\ny_pred = rf_model.predict(X_test)\n\n\nprint(\"\\nClassification Report:\\n\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}